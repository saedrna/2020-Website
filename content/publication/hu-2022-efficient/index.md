---
# Documentation: https://wowchemy.com/docs/managing-content/

title: Efficient Procedural Modelling of Building Façades Based on Windows from Sketches
subtitle: ''
summary: ''
authors:
- __Han Hu__
- Bo Feng
- Bo Xu&ast;
- Qing Zhu
- Xuming Ge
- Min Chen
tags:
- building façade reconstruction
- interactive sketching
- oblique photogrammetry
- procedural modelling
- windows
categories: []
date: '2022-01-01'
lastmod: 2022-09-19T20:48:06+08:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2022-09-19T12:48:06.653692Z'
publication_types:
- '2'
abstract: 'Realistic and delicate window models are in great demand for detailed LOD-3
  urban reconstruction. However, current research tends to oversimplify the window
  models due to the difficulties in describing the complex window types and structure
  parameters. This work proposes a sketch-based window reconstruction method for procedural
  façade modelling. With a rough sketch of the target windows, the method can quickly
  identify the window type and estimate the grammar parameters, eventually producing
  detailed 3D models with textures. The whole task is adopted within two neural networks:
  the classification network to judge the grammar category and the regression network
  to estimate the parameter value. The non-photorealistic rendering technology adopted
  in the present work can generate abundant training datasets, and meanwhile, the
  attention mechanism is used to identify the grammar parameters precisely. Experimental
  results on various data verify the effectiveness and accuracy of the proposed approach.'
publication: '*The Photogrammetric Record*'
doi: 10.1111/phor.12425
---
